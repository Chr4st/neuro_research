# Data Directory

This directory should contain ADNI data files. **No actual data files are included in this repository** due to data sharing restrictions.

## Expected Data Formats

### Cortical Thickness Data

Expected format: CSV file with the following structure:

```
SubjectID,ROI_1,ROI_2,...,ROI_N,Age,Sex,Diagnosis,...
SUBJ_001,2.5,2.3,...,2.1,75,M,CN,...
SUBJ_002,2.1,1.9,...,1.8,78,F,MCI,...
...
```

- **SubjectID**: Unique subject identifier
- **ROI_1, ROI_2, ..., ROI_N**: Cortical thickness values for each ROI (in mm)
- Additional columns (Age, Sex, Diagnosis, etc.) are preserved as metadata

### Structural Connectome

Expected format: NumPy array (`.npy`) or CSV file

- **Shape**: `(n_rois, n_rois)` - symmetric adjacency matrix
- **Values**: Non-negative edge weights (connection strengths)
- **Diagonal**: Should be zero (no self-loops)

### ROI Labels (Optional)

Text file with one ROI label per line:

```
Left_Frontal_Pole
Right_Frontal_Pole
Left_Precentral_Gyrus
...
```

## Mock Data

For testing and demonstration, the scripts can generate mock data using the `--use-mock` flag. This creates synthetic data with realistic properties but does not represent real ADNI data.

## Data Access

To use real ADNI data:

1. Obtain ADNI data access from [adni.loni.usc.edu](https://adni.loni.usc.edu/)
2. Process your data into the expected formats described above
3. Update the configuration file (`configs/default.yaml`) with paths to your data files
4. Run the pipeline scripts

## Directory Structure

```
data/
├── raw/              # Raw ADNI files (not included)
├── processed/        # Processed data files (generated by scripts)
│   ├── cortical_thickness_processed.npy
│   ├── connectome.npy
│   ├── laplacian.npy
│   └── metadata.csv
└── README.md         # This file
```

